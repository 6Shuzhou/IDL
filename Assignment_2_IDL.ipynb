{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-KqY50zyzy",
        "outputId": "61396b69-b4c3-472e-cb0c-c05b8a385558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669706 (2.55 MB)\n",
            "Trainable params: 669706 (2.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-16 17:17:03.150664: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 169344000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 3s 7ms/step - loss: 0.5807 - accuracy: 0.7870 - val_loss: 53.1612 - val_accuracy: 0.8252\n",
            "Epoch 2/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.4084 - accuracy: 0.8496 - val_loss: 51.0438 - val_accuracy: 0.8525\n",
            "Epoch 3/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.3663 - accuracy: 0.8647 - val_loss: 59.0059 - val_accuracy: 0.8364\n",
            "Epoch 4/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.3444 - accuracy: 0.8728 - val_loss: 52.5024 - val_accuracy: 0.8575\n",
            "Epoch 5/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.3264 - accuracy: 0.8801 - val_loss: 67.7991 - val_accuracy: 0.8422\n",
            "Epoch 6/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.3140 - accuracy: 0.8831 - val_loss: 41.5028 - val_accuracy: 0.8661\n",
            "Epoch 7/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.3020 - accuracy: 0.8884 - val_loss: 51.3707 - val_accuracy: 0.8741\n",
            "Epoch 8/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2953 - accuracy: 0.8916 - val_loss: 52.8400 - val_accuracy: 0.8633\n",
            "Epoch 9/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2877 - accuracy: 0.8936 - val_loss: 55.9313 - val_accuracy: 0.8690\n",
            "Epoch 10/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2790 - accuracy: 0.8963 - val_loss: 50.1036 - val_accuracy: 0.8781\n",
            "Epoch 11/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2740 - accuracy: 0.8984 - val_loss: 69.9943 - val_accuracy: 0.8500\n",
            "Epoch 12/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2671 - accuracy: 0.9002 - val_loss: 55.1674 - val_accuracy: 0.8707\n",
            "Epoch 13/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2637 - accuracy: 0.9024 - val_loss: 67.3113 - val_accuracy: 0.8665\n",
            "Epoch 14/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2579 - accuracy: 0.9046 - val_loss: 64.9654 - val_accuracy: 0.8793\n",
            "Epoch 15/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.2546 - accuracy: 0.9049 - val_loss: 53.0602 - val_accuracy: 0.8749\n",
            "Epoch 16/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2496 - accuracy: 0.9079 - val_loss: 64.2080 - val_accuracy: 0.8858\n",
            "Epoch 17/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2483 - accuracy: 0.9101 - val_loss: 53.2473 - val_accuracy: 0.8813\n",
            "Epoch 18/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2474 - accuracy: 0.9092 - val_loss: 57.8464 - val_accuracy: 0.8775\n",
            "Epoch 19/20\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.2386 - accuracy: 0.9127 - val_loss: 65.2165 - val_accuracy: 0.8802\n",
            "Epoch 20/20\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2354 - accuracy: 0.9143 - val_loss: 66.1059 - val_accuracy: 0.8831\n",
            "Test loss: 66.10587310791016\n",
            "Test accuracy: 0.8830999732017517\n"
          ]
        }
      ],
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets, and create a valid set\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()\n",
        "X_valid, x_train = X_train_full[:6000] / 255.0, X_train_full[6000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:6000], y_train_full[6000:]\n",
        "x_train = x_train.reshape(54000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# define the class names\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        " \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMU2_90ba6PK",
        "outputId": "2e5c4a40-3aee-4b7a-bc03-89ef80a2f24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669706 (2.55 MB)\n",
            "Trainable params: 669706 (2.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-16 17:17:59.455430: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "461/469 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9209"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-16 17:18:02.656739: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2544 - accuracy: 0.9215 - val_loss: 0.0962 - val_accuracy: 0.9690\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1033 - accuracy: 0.9679 - val_loss: 0.0990 - val_accuracy: 0.9698\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0740 - accuracy: 0.9773 - val_loss: 0.0671 - val_accuracy: 0.9789\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 0.0684 - val_accuracy: 0.9802\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 0.0727 - val_accuracy: 0.9792\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 0.0724 - val_accuracy: 0.9800\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0618 - val_accuracy: 0.9834\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0704 - val_accuracy: 0.9827\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0634 - val_accuracy: 0.9861\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0784 - val_accuracy: 0.9824\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0809 - val_accuracy: 0.9820\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0727 - val_accuracy: 0.9841\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0726 - val_accuracy: 0.9848\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0786 - val_accuracy: 0.9845\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0816 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0998 - val_accuracy: 0.9809\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0727 - val_accuracy: 0.9859\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0906 - val_accuracy: 0.9823\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0881 - val_accuracy: 0.9853\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0826 - val_accuracy: 0.9854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-16 17:19:00.125474: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.08255904912948608\n",
            "Test accuracy: 0.9854000210762024\n"
          ]
        }
      ],
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
